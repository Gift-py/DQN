Action Space: Discrete(2)
State space: Box([-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38], [4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38], (4,), float32)
state_shape:  (4,)
state_shape:  (4,)
Total training rewards: 19.0 after n steps = 0 with final reward = 1.0
Total training rewards: 22.0 after n steps = 1 with final reward = 1.0
Total training rewards: 14.0 after n steps = 2 with final reward = 1.0
Total training rewards: 15.0 after n steps = 3 with final reward = 1.0
Total training rewards: 22.0 after n steps = 4 with final reward = 1.0
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 97ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
Total training rewards: 28.0 after n steps = 5 with final reward = 1.0
Copying main network weights to the target network weights
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
Total training rewards: 18.0 after n steps = 6 with final reward = 1.0
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
Total training rewards: 14.0 after n steps = 7 with final reward = 1.0
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
Total training rewards: 33.0 after n steps = 8 with final reward = 1.0
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
Total training rewards: 54.0 after n steps = 9 with final reward = 1.0
Copying main network weights to the target network weights
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
Total training rewards: 63.0 after n steps = 10 with final reward = 1.0
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
Total training rewards: 32.0 after n steps = 11 with final reward = 1.0
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
Total training rewards: 18.0 after n steps = 12 with final reward = 1.0
Copying main network weights to the target network weights
Total training rewards: 10.0 after n steps = 13 with final reward = 1.0
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
Total training rewards: 23.0 after n steps = 14 with final reward = 1.0
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
Total training rewards: 14.0 after n steps = 15 with final reward = 1.0
Action Space: Discrete(2)
State space: Box([-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38], [4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38], (4,), float32)
state_shape:  (4,)
state_shape:  (4,)
Total training rewards: 45.0 after n steps = 0 with final reward = 1.0
Total training rewards: 25.0 after n steps = 1 with final reward = 1.0
Total training rewards: 33.0 after n steps = 2 with final reward = 1.0
Copying main network weights to the target network weights
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 103ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 18ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
Total training rewards: 90.0 after n steps = 3 with final reward = 1.0
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
Total training rewards: 34.0 after n steps = 4 with final reward = 1.0
Copying main network weights to the target network weights
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
Total training rewards: 19.0 after n steps = 5 with final reward = 1.0
Total training rewards: 22.0 after n steps = 6 with final reward = 1.0
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
Total training rewards: 12.0 after n steps = 7 with final reward = 1.0
Total training rewards: 15.0 after n steps = 8 with final reward = 1.0
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
Total training rewards: 13.0 after n steps = 9 with final reward = 1.0
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
Total training rewards: 14.0 after n steps = 10 with final reward = 1.0
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
Total training rewards: 12.0 after n steps = 11 with final reward = 1.0
Copying main network weights to the target network weights
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
Total training rewards: 15.0 after n steps = 12 with final reward = 1.0
Total training rewards: 15.0 after n steps = 13 with final reward = 1.0
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
Total training rewards: 13.0 after n steps = 14 with final reward = 1.0
Action Space: Discrete(2)
State space: Box([-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38], [4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38], (4,), float32)
state_shape:  (4,)
state_shape:  (4,)
Total training rewards: 12.0 after n steps = 0 with final reward = 1.0
Total training rewards: 59.0 after n steps = 1 with final reward = 1.0
Total training rewards: 24.0 after n steps = 2 with final reward = 1.0
[-0.0056274   0.6080937   0.02947099 -0.7607816 ]
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 97ms/step
Total training rewards: 20.0 after n steps = 3 with final reward = 1.0
Copying main network weights to the target network weights
[ 0.07169294  0.8329672  -0.12737478 -1.2833312 ]
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
Total training rewards: 12.0 after n steps = 4 with final reward = 1.0
Total training rewards: 17.0 after n steps = 5 with final reward = 1.0
[ 0.01009564  0.20190364  0.04725144 -0.25665104]
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
[ 0.01454959  0.3936344   0.04782344 -0.47487113]
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[ 0.18310489  1.1786488  -0.1689115  -1.7651725 ]
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
Total training rewards: 22.0 after n steps = 6 with final reward = 1.0
[-0.01123246  0.23987778  0.00258399 -0.24912551]
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[-0.03663    -0.3459971   0.06980647  0.6414482 ]
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
Total training rewards: 27.0 after n steps = 7 with final reward = 1.0
Total training rewards: 15.0 after n steps = 8 with final reward = 1.0
[ 0.06765922  0.22950122 -0.02863281 -0.34335652]
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
[ 0.07046584 -0.15881553 -0.03391984  0.19973733]
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
Total training rewards: 28.0 after n steps = 9 with final reward = 1.0
Copying main network weights to the target network weights
[-0.02782137  0.16106266  0.03878164 -0.24669844]
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
Total training rewards: 22.0 after n steps = 10 with final reward = 1.0
[ 0.00262141 -0.00046321  0.02313145  0.06036005]
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[-0.00530416 -0.19774336  0.04252107  0.40093723]
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
[0.08885668 0.3488847  0.16114587 0.38171816]
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 21ms/step
[ 0.09887209 -0.04511958  0.18319143  1.0612553 ]
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
[ 0.0979697  -0.24213183  0.20441654  1.4053864 ]
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
Total training rewards: 44.0 after n steps = 11 with final reward = 1.0
[-0.05979503 -0.54775774  0.10772348  1.0288496 ]
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
Total training rewards: 15.0 after n steps = 12 with final reward = 1.0
[-0.01221585 -0.03314423 -0.0549638  -0.08427336]
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
[-0.02586157 -0.22587746 -0.04354053  0.1560046 ]
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
[-0.03037912 -0.42034984 -0.04042044  0.4346398 ]
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
[-0.04386207 -0.22381099 -0.03259831  0.11032291]
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
Total training rewards: 29.0 after n steps = 13 with final reward = 1.0
Copying main network weights to the target network weights
(array([-0.03621817, -0.00166337, -0.02517476, -0.03793001], dtype=float32), {})
